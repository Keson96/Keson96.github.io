<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>🔨局部搜索方法 | MayMoon</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="局部搜索方法局部搜索方法是解决无约束优化的一种方法，一般只能得到局部最优解。如果自变量 $x$ 是一维的，即一个实数，我们要优化 $f(x)$ ，就只能将 $x$ 向左移动或向右移动，如下图所示。我们希望$f(x)$最大，就将$x$向使能使$f(x)$增大的方向移动（左或右）。对于A和B，它们分别向右向左移动，最终到达全局最优点P；而对于C和D，它们只能到达局部最优点Q。所以这些方法称为局部搜索方">
<meta property="og:type" content="article">
<meta property="og:title" content="🔨局部搜索方法">
<meta property="og:url" content="http://yoursite.com/2000/07/05/局部搜索算法/index.html">
<meta property="og:site_name" content="MayMoon">
<meta property="og:description" content="局部搜索方法局部搜索方法是解决无约束优化的一种方法，一般只能得到局部最优解。如果自变量 $x$ 是一维的，即一个实数，我们要优化 $f(x)$ ，就只能将 $x$ 向左移动或向右移动，如下图所示。我们希望$f(x)$最大，就将$x$向使能使$f(x)$增大的方向移动（左或右）。对于A和B，它们分别向右向左移动，最终到达全局最优点P；而对于C和D，它们只能到达局部最优点Q。所以这些方法称为局部搜索方">
<meta property="og:image" content="http://i.imgur.com/c0U62Fz.png">
<meta property="og:updated_time" content="2016-09-28T10:46:12.963Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="🔨局部搜索方法">
<meta name="twitter:description" content="局部搜索方法局部搜索方法是解决无约束优化的一种方法，一般只能得到局部最优解。如果自变量 $x$ 是一维的，即一个实数，我们要优化 $f(x)$ ，就只能将 $x$ 向左移动或向右移动，如下图所示。我们希望$f(x)$最大，就将$x$向使能使$f(x)$增大的方向移动（左或右）。对于A和B，它们分别向右向左移动，最终到达全局最优点P；而对于C和D，它们只能到达局部最优点Q。所以这些方法称为局部搜索方">
<meta name="twitter:image" content="http://i.imgur.com/c0U62Fz.png">
  
    <link rel="alternate" href="/atom.xml" title="MayMoon" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">MayMoon</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">随便写写</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="Flux RSS"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Rechercher"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-局部搜索算法" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2000/07/05/局部搜索算法/" class="article-date">
  <time datetime="2000-07-05T11:54:01.000Z" itemprop="datePublished">2000-07-05</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Under-Construction/">Under Construction</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      🔨局部搜索方法
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="局部搜索方法"><a href="#局部搜索方法" class="headerlink" title="局部搜索方法"></a>局部搜索方法</h1><p>局部搜索方法是解决无约束优化的一种方法，一般只能得到局部最优解。如果自变量 $x$ 是一维的，即一个实数，我们要优化 $f(x)$ ，就只能将 $x$ 向左移动或向右移动，如下图所示。我们希望$f(x)$最大，就将$x$向使能使$f(x)$增大的方向移动（左或右）。对于A和B，它们分别向右向左移动，最终到达全局最优点P；而对于C和D，它们只能到达局部最优点Q。所以这些方法称为局部搜索方法。一般来说，$x$ 是 $n$ 维向量，即$x \in \mathbb R^n$，这样的话，$x$可以移动的方向就有很多个。<br>$n$维情况下，$f(x):\mathbb R^n \to \mathbb R$</p>
<p><img src="http://i.imgur.com/c0U62Fz.png" alt=""></p>
<p>局部搜索算法的一般过程：</p>
<ul>
<li>找到初始点 $x^{(0)} \in \mathcal S$</li>
<li>设 $k=0$</li>
<li>$\mathtt {repeat}$<ul>
<li>评价 $f(x^{(k)})$ </li>
<li>计算一个搜索方向 $q_k$</li>
<li>计算步长 $\lambda_k$</li>
<li>令$x^{(k+1)}$为$x^{(k)}+\lambda_kq_k$</li>
<li>$k = k + 1$</li>
</ul>
</li>
<li>$\mathtt {until}$终止条件满足</li>
<li>返回$x^{(k)}$作为解</li>
</ul>
<blockquote>
<p>$x^{(k)}$指的是迭代$k$次后$x$的取值<br>终止条件一般使用精度，即梯度值；也就是说，再进行优化，每一步优化的效果微乎其微，小于一个我们设定好的值时，便停止迭代。另一种常用的终止条件就是显式地规定迭代次数。</p>
</blockquote>
<h2 id="梯度下降法（Gradient-descent-最速下降法-steepest-descent）"><a href="#梯度下降法（Gradient-descent-最速下降法-steepest-descent）" class="headerlink" title="梯度下降法（Gradient descent / 最速下降法 steepest descent）"></a>梯度下降法（Gradient descent / 最速下降法 steepest descent）</h2><p>梯度下降法是利用不断更新$x$的值，使得$f(x)$不断变小，直到收敛。由于负梯度方向是使函数值下降最快的方向，所以在迭代的每一步，以负梯度方向更新$x$的值。</p>
<h4 id="为什么负梯度下降速度最快"><a href="#为什么负梯度下降速度最快" class="headerlink" title="为什么负梯度下降速度最快"></a>为什么负梯度下降速度最快</h4><p>若第$k$次迭代值为$x^{(k)}$，则可以讲$f(x)$在$x^{(k)}$附近进行一阶泰勒展开：<br>$$f(x) = f(x^{(k)}) + g_k \cdot (x-x^{(k)})$$<br>其中，$g_k=g(x^{(k)})=\nabla f(x^{(k)})$为$f(x)$在$x^{(k)}$的梯度。上面的式子是一维的情况，下面的式子是$n$维的情况（即$x$不再是一个实数，而是一个$n$维向量）<br>$$f(x) = f(x^{(k)}) + g_k^T \cdot (x-x^{(k)})$$</p>
<blockquote>
<p>当$x$是n维向量时，对$f(x)$求导的结果是:<br>$$\nabla f(x) = \begin{pmatrix}<br>\frac{\partial f(x)}{\partial x_1}\ \\<br>\vdots \\<br>\frac{\partial f(x)}{\partial x_n}<br>\end{pmatrix}$$<br>由于$g_k = \nabla f(x^{(k)})$是一个列向量，而$x-x^{(k)}$也是列向量，所以必须将$g_k$转置，即为式中的$g_k^T$，才可以相乘得到一个实数</p>
</blockquote>
<p>记 $d_k= x-x^{(k)}$，则我们要最小化$g_k \cdot d_k$，才能使$f(x)$下降得最快。<br>由于 $d_k$和$g_k$都是$n$维向量，所以，当$d_k = -g_k$时，两者乘积最小，为$-\Vert{g_k}\Vert^2$，所以说负梯度下降速度最快。</p>
<h3 id="算法步骤"><a href="#算法步骤" class="headerlink" title="算法步骤"></a>算法步骤</h3><p>输入：目标函数$f(x)$，梯度函数$g(x)=\nabla f(x)$，计算精度$\epsilon$<br>输出：$f(x)$的极小值点$x^{*}$<br>(1) 取初始值$x^{(0)} \in \mathbb R^n$，置$k=0$<br>(2) 计算$f(x^{(k)})$<br>(3) 计算梯度$g_k=g(x^{(k)})$，当$\Vert g_k\Vert &lt; \epsilon$时，停止迭代，令$x^{*}=x^{(k)}$；否则，令$p_k=-g(x^{(k)})$，求$\lambda_k$，使$$f(x^{(k)}+\lambda_kp_k)=\min_{\lambda&gt;=0}f(x^{(k)}+\lambda p_k)$$<br>(4) 置$x^{(k+1)}=x{(k)}+\lambda_kp_k$，计算$f(x^{(k+1)})$<br>当$\Vert f(x^{(k+1)})-f(x^{(k)})\Vert&lt;\epsilon$或$\Vert x^{(k+1)}-x^{(k)}\Vert&lt;\epsilon$时，停止迭代，令$x^{*}=x^{(k+1)}$<br>(5) 否则，置$k=k+1$，转至(3)</p>
<h3 id="梯度下降法的讨论"><a href="#梯度下降法的讨论" class="headerlink" title="梯度下降法的讨论"></a>梯度下降法的讨论</h3><p>当目标函数是凸函数时，梯度下降法的解是全局最优解。一般情况下，其解不保证是全局最优解。梯度下降法只利用了一阶导数的信息，其收敛速度未必是很快的。（详见参考资料2）</p>
<p>参考资料：</p>
<ol>
<li><p><a href="http://www.codelast.com/%e5%8e%9f%e5%88%9b%e6%9c%80%e9%80%9f%e4%b8%8b%e9%99%8d%e6%b3%95%ef%bc%8c%e7%89%9b%e9%a1%bf%e6%b3%95%ef%bc%8c%e5%85%b1%e8%bd%ad%e6%96%b9%e5%90%91%e6%b3%95%ef%bc%8c%e5%85%b1%e8%bd%ad%e6%a2%af%e5%ba%a6/" target="_blank" rel="external">[原创]最速下降法/steepest descent，牛顿法/newton，共轭方向法/conjugate direction，共轭梯度法/conjugate gradient 及其他</a></p>
</li>
<li><p><a href="http://www.codelast.com/%e5%8e%9f%e5%88%9b-%e5%86%8d%e8%b0%88-%e6%9c%80%e9%80%9f%e4%b8%8b%e9%99%8d%e6%b3%95%e6%a2%af%e5%ba%a6%e6%b3%95steepest-descent/" target="_blank" rel="external">[原创] 再谈 最速下降法/梯度法/Steepest Descent</a></p>
</li>
<li><p>《统计学习方法》附录A</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2000/07/05/局部搜索算法/" data-id="civ37veby002xogkr867e3zzb" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/04/15/2016-04-15-1.3-Bags-Queues-Stacks/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Récent</strong>
      <div class="article-nav-title">
        
          1-3 Bags,Queues and Stacks
        
      </div>
    </a>
  
  
    <a href="/2000/05/16/收缩技术/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Ancien</strong>
      <div class="article-nav-title">🔨收缩技术(Shrinkage Methods)</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Catégories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/CS229-notes/">CS229 notes</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/LeetCode笔记/">LeetCode笔记</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning-Course-notes/">Machine Learning Course notes</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/PRML-notes/">PRML notes</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Under-Construction/">Under Construction</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/《Algorithms》-notes/">《Algorithms》 notes</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/优化算法/">优化算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/具体数学笔记/">具体数学笔记</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/杂记/">杂记</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Mot-clés</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/a-algorithm/">a* algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/adaboost/">adaboost</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/add-digits/">add digits</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/algorithm/">algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/arithmetic-expression/">arithmetic expression</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/bag/">bag</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/bagging/">bagging</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/batch-gradient-decent/">batch gradient decent</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/beam-search/">beam search</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/best-first-search/">best-first search</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/bfs/">bfs</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/bias/">bias</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/binary-search/">binary search</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/binary-search-tree/">binary search tree</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/curve-fitting/">curve fitting</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dag/">dag</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/data-structure/">data structure</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dfs/">dfs</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/directed-graph/">directed graph</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/exponential-family-distribution/">exponential family distribution</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/forward-stagewise/">forward stagewise</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/gbdt/">gbdt</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/general-linear-model/">general linear model</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hanoi-tower/">hanoi tower</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hash/">hash</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/heap-sort/">heap sort</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/heuristic-algorithm/">heuristic algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo/">hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/insertion-sort/">insertion sort</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/josephus-problem/">josephus problem</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/knight-tour/">knight tour</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kosaraju-s-algorithm/">kosaraju's algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kruskal-s-algorithm/">kruskal's algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/lars/">lars</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/lasso/">lasso</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/leetcode/">leetcode</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linear-regression/">linear regression</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/lingo/">lingo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/logistic-regression/">logistic regression</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/lwr/">lwr</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/">machine learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mathjax/">mathjax</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mst/">mst</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/neural-network/">neural network</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nim-game/">nim game</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/physics/">physics</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/prim-s-algorithm/">prim's algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/priority-queue/">priority queue</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/prml/">prml</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/queue/">queue</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/random-forest/">random forest</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/selection-sort/">selection sort</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/shell-sort/">shell sort</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/single-number/">single number</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/stack/">stack</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/stochastic-gradient-decent/">stochastic gradient decent</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/support-vector-machine/">support vector machine</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/symbol-table/">symbol table</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/topological-sort/">topological sort</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/undirected-graph/">undirected graph</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/variance/">variance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/递归问题/">递归问题</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/集成学习/">集成学习</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Nuage de mot-clés</h3>
    <div class="widget tagcloud">
      <a href="/tags/a-algorithm/" style="font-size: 10px;">a* algorithm</a> <a href="/tags/adaboost/" style="font-size: 10px;">adaboost</a> <a href="/tags/add-digits/" style="font-size: 10px;">add digits</a> <a href="/tags/algorithm/" style="font-size: 20px;">algorithm</a> <a href="/tags/arithmetic-expression/" style="font-size: 10px;">arithmetic expression</a> <a href="/tags/bag/" style="font-size: 10px;">bag</a> <a href="/tags/bagging/" style="font-size: 10px;">bagging</a> <a href="/tags/batch-gradient-decent/" style="font-size: 10px;">batch gradient decent</a> <a href="/tags/beam-search/" style="font-size: 10px;">beam search</a> <a href="/tags/best-first-search/" style="font-size: 10px;">best-first search</a> <a href="/tags/bfs/" style="font-size: 10px;">bfs</a> <a href="/tags/bias/" style="font-size: 10px;">bias</a> <a href="/tags/binary-search/" style="font-size: 10px;">binary search</a> <a href="/tags/binary-search-tree/" style="font-size: 10px;">binary search tree</a> <a href="/tags/curve-fitting/" style="font-size: 10px;">curve fitting</a> <a href="/tags/dag/" style="font-size: 10px;">dag</a> <a href="/tags/data-structure/" style="font-size: 10px;">data structure</a> <a href="/tags/dfs/" style="font-size: 13.33px;">dfs</a> <a href="/tags/directed-graph/" style="font-size: 10px;">directed graph</a> <a href="/tags/exponential-family-distribution/" style="font-size: 10px;">exponential family distribution</a> <a href="/tags/forward-stagewise/" style="font-size: 10px;">forward stagewise</a> <a href="/tags/gbdt/" style="font-size: 10px;">gbdt</a> <a href="/tags/general-linear-model/" style="font-size: 10px;">general linear model</a> <a href="/tags/hanoi-tower/" style="font-size: 10px;">hanoi tower</a> <a href="/tags/hash/" style="font-size: 10px;">hash</a> <a href="/tags/heap-sort/" style="font-size: 10px;">heap sort</a> <a href="/tags/heuristic-algorithm/" style="font-size: 10px;">heuristic algorithm</a> <a href="/tags/hexo/" style="font-size: 13.33px;">hexo</a> <a href="/tags/insertion-sort/" style="font-size: 10px;">insertion sort</a> <a href="/tags/josephus-problem/" style="font-size: 10px;">josephus problem</a> <a href="/tags/knight-tour/" style="font-size: 10px;">knight tour</a> <a href="/tags/kosaraju-s-algorithm/" style="font-size: 10px;">kosaraju's algorithm</a> <a href="/tags/kruskal-s-algorithm/" style="font-size: 10px;">kruskal's algorithm</a> <a href="/tags/lars/" style="font-size: 13.33px;">lars</a> <a href="/tags/lasso/" style="font-size: 13.33px;">lasso</a> <a href="/tags/leetcode/" style="font-size: 10px;">leetcode</a> <a href="/tags/linear-regression/" style="font-size: 10px;">linear regression</a> <a href="/tags/lingo/" style="font-size: 10px;">lingo</a> <a href="/tags/logistic-regression/" style="font-size: 10px;">logistic regression</a> <a href="/tags/lwr/" style="font-size: 10px;">lwr</a> <a href="/tags/machine-learning/" style="font-size: 16.67px;">machine learning</a> <a href="/tags/mathjax/" style="font-size: 10px;">mathjax</a> <a href="/tags/mst/" style="font-size: 10px;">mst</a> <a href="/tags/neural-network/" style="font-size: 10px;">neural network</a> <a href="/tags/nim-game/" style="font-size: 10px;">nim game</a> <a href="/tags/physics/" style="font-size: 10px;">physics</a> <a href="/tags/prim-s-algorithm/" style="font-size: 10px;">prim's algorithm</a> <a href="/tags/priority-queue/" style="font-size: 10px;">priority queue</a> <a href="/tags/prml/" style="font-size: 10px;">prml</a> <a href="/tags/queue/" style="font-size: 10px;">queue</a> <a href="/tags/random-forest/" style="font-size: 10px;">random forest</a> <a href="/tags/selection-sort/" style="font-size: 10px;">selection sort</a> <a href="/tags/shell-sort/" style="font-size: 10px;">shell sort</a> <a href="/tags/single-number/" style="font-size: 10px;">single number</a> <a href="/tags/stack/" style="font-size: 10px;">stack</a> <a href="/tags/stochastic-gradient-decent/" style="font-size: 10px;">stochastic gradient decent</a> <a href="/tags/support-vector-machine/" style="font-size: 10px;">support vector machine</a> <a href="/tags/symbol-table/" style="font-size: 13.33px;">symbol table</a> <a href="/tags/topological-sort/" style="font-size: 10px;">topological sort</a> <a href="/tags/undirected-graph/" style="font-size: 10px;">undirected graph</a> <a href="/tags/variance/" style="font-size: 10px;">variance</a> <a href="/tags/递归问题/" style="font-size: 10px;">递归问题</a> <a href="/tags/集成学习/" style="font-size: 10px;">集成学习</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">June 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2000/07/">July 2000</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2000/05/">May 2000</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Articles récents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/11/04/2016-11-04-Gradient-Boosting/">梯度提升(Gradient Boosting)</a>
          </li>
        
          <li>
            <a href="/2016/10/28/2016-10-28-lars-lasso-stagewise/">LARS与Lasso和Forward Stagewise</a>
          </li>
        
          <li>
            <a href="/2016/10/26/2016-10-26-Least-Angle-Regression/">最小角回归(Least Angle Regression)</a>
          </li>
        
          <li>
            <a href="/2016/10/17/2016-10-17-集成学习算法/">集成学习算法(Ensemble Learning)</a>
          </li>
        
          <li>
            <a href="/2016/10/14/2016-10-14-General-Linear-Model/">一般线性模型(General Linear Model)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Wang Kx<br>
      Propulsé by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>