<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>贝叶斯与多项式拟合 | MayMoon</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="本文主要介绍从贝叶斯理论角度看多项式曲线拟合，不涉及多项式曲线拟合的具体细节。">
<meta property="og:type" content="article">
<meta property="og:title" content="贝叶斯与多项式拟合">
<meta property="og:url" content="http://yoursite.com/2016/09/26/2016-09-26-贝叶斯与曲线拟合/index.html">
<meta property="og:site_name" content="MayMoon">
<meta property="og:description" content="本文主要介绍从贝叶斯理论角度看多项式曲线拟合，不涉及多项式曲线拟合的具体细节。">
<meta property="og:image" content="http://i.imgur.com/otmQ2ia.png">
<meta property="og:updated_time" content="2016-09-28T10:35:49.154Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="贝叶斯与多项式拟合">
<meta name="twitter:description" content="本文主要介绍从贝叶斯理论角度看多项式曲线拟合，不涉及多项式曲线拟合的具体细节。">
<meta name="twitter:image" content="http://i.imgur.com/otmQ2ia.png">
  
    <link rel="alternate" href="/atom.xml" title="MayMoon" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">MayMoon</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">随便写写</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="Flux RSS"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Rechercher"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-2016-09-26-贝叶斯与曲线拟合" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/09/26/2016-09-26-贝叶斯与曲线拟合/" class="article-date">
  <time datetime="2016-09-26T11:54:01.000Z" itemprop="datePublished">2016-09-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/PRML-notes/">PRML notes</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      贝叶斯与多项式拟合
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本文主要介绍从贝叶斯理论角度看多项式曲线拟合，不涉及多项式曲线拟合的具体细节。</p>
<a id="more"></a>
<h2 id="多项式曲线拟合"><a href="#多项式曲线拟合" class="headerlink" title="多项式曲线拟合"></a>多项式曲线拟合</h2><p>假设给定了一个包含$N$个$x$的训练集，记为 $\mathbf{x}\equiv (x_1,\cdots,x_N)^T$，同时有对应的目标值 $\mathbf{t}\equiv (t_1,\cdots,t_N)^T$。我们想找到一个函数能最好地拟合现有这组数据，以便给定一个新的$\hat{x}$，我们可以通过这个函数来给出一个预测值$\hat{t}$。<br>现在，我们仅考虑用多项式函数去拟合这组数据，即：<br>$$y(x,\mathbf{w})=w_0+w_1x+w_2x^2+\cdots+w_Mx^M=\sum\limits_{j=0}^Mw_jx^j\tag{1}$$<br>其中$M$代表多项式的阶数，多项式的系数$w_0,\cdots,w_M$可以简记为$\mathbf{w}$。注意到函数$y(x,\mathbf{w})$尽管是关于$x$的非线性函数，却是关于$\mathbf{w}$的线性函数。<br>多项式系数$\mathbf{w}$的值可以通过拟合训练集来确定。我们用一个误差函数来度量预测值与训练集之间的误差，然后通过最小化这个误差函数来进行拟合。一个简单而常用的误差函数是计算训练集中每个数据点与预测值之间差值平方的和，即：<br>$$E(\mathbf{w})=\frac{1}{2}\sum\limits_{n=1}^N\{y(x_n,\mathbf{w})-t_n\}^2\tag{2}$$这里添加了一个乘子$\frac{1}{2}$是为了方便之后求导。</p>
<h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><p>进行拟合时，如果多项式阶数较高，就可能会发生过拟合。我们可以将多项式的阶数这一因素加入到误差函数中，用来防止过拟合。改进后的误差函数为：<br>$$E(\mathbf{w})=\frac{1}{2}\sum\limits_{n=1}^N\{y(x_n,\mathbf{w})-t_n\}^2+\frac{\lambda}{2}||\mathbf{w}||^2\tag{3}$$</p>
<h2 id="贝叶斯理论"><a href="#贝叶斯理论" class="headerlink" title="贝叶斯理论"></a>贝叶斯理论</h2><p>在经典概率论中，概率指的是随机重复事件发生的频率。而从贝叶斯理论的角度去看，概率提供了对不确定性的一种度量。<br>利用贝叶斯理论，我们可以从不断获得的数据（事实）中得到经验，来修改我们对不确定性的度量。<br>举一个简单的例子：有2个箱子A和B，其中A箱子有2个红球，1个白球；B箱子有2个白球，1个红球。现在我们等概率地从任一个箱子中取出一个球。在观察这个球的颜色之前，我们认为这个球来自A箱子和来自B箱子的概率相同，即$p(A)=p(B)=0.5$；然而，如果我们观察到这个球是红色，那么概率就会变化，此时小球来自A箱的概率为$\frac{2}{3}$，而来自B箱的概率仅为$\frac{1}{3}$。<br>回到曲线拟合的例子，我们在观察训练数据集之前，对$\mathbf{w}$取值的概率分布有一个预测，记作$p(\mathbf{w})$，称之为<strong>先验概率</strong>（在观察数据前）。有一组观察到的数据$\mathcal{D}=\{t_1,\cdots,t_N\}$，在观察数据后对$\mathbf{w}$的预测变为$p(\mathbf{w}|\mathcal{D})$，称之为<strong>后验概率</strong>（在观察数据后）。<br>贝叶斯理论的核心是给出了先验概率与后验概率间的关系，即$$p(\mathbf{w}|\mathcal{D})=\cfrac{p(\cal{D}|\mathbf{w})p(\mathbf{w})}{p(\mathcal{D})} \tag{4}$$<br>其中，等式右边的$p(\cal{D}|\mathbf{w})$称为<strong>似然函数</strong>，它可以看作是一个关于$\mathbf{w}$的函数，它描述了在不同的$\mathbf{w}$下产生这样的数据集$\mathcal{D}$的可能性。注意这不是关于$\mathbf{w}$的概率分布，所以它关于$\mathbf{w}$的积分不一定等于1。<br>我们可以用文字来描述贝叶斯理论，即$$\mathrm{posterior}\propto\mathrm{likelihood}\times\mathrm{prior}\tag{5}$$<br>将所有的量看成关于$\mathbf{w}$的函数，$p(\mathcal{D})$就是一个常数系数，它用来保证等式左侧的后验概率积分后等于1。如果给(4)式左右两边积分，我们就可以用先验概率和似然函数来表示这个系数$$p(\mathcal{D})=\int p(\cal{D}|\mathbf{w})p(\mathbf{w})\,d\mathbf{w}\tag{6}$$</p>
<h2 id="回到多项式曲线拟合"><a href="#回到多项式曲线拟合" class="headerlink" title="回到多项式曲线拟合"></a>回到多项式曲线拟合</h2><p>下面我们从贝叶斯的视角再来看多项式曲线拟合。回顾一下多项式曲线拟合的问题描述：假设给定了一个包含$N$个$x$的训练集，记为 $\mathbf{x}\equiv (x_1,\cdots,x_N)^T$，同时有对应的目标值 $\mathbf{t}\equiv (t_1,\cdots,t_N)^T$。我们的目标是对给定的一个新$\hat{x}$，能得到一个预测值$\hat{t}$。与之前不同，我们用目标变量$t$的概率分布来描述不确定性。<br>假设对给定的$x$，对应的$t$服从均值为$y(x,\mathbf{w})$的正态分布，其中$y(x,\mathbf{w})$即式(1)中得到的结果$$p(t|x,\mathbf{w},\beta)=\mathcal{N}(t|y(x,\mathbf{w}),\beta^{-1})\tag{7}$$这里的$\beta$表示正态分布的精度，等于方差的倒数。<br>下图更好地说明了这一假设：<br><img src="http://i.imgur.com/otmQ2ia.png" width="400" height="300"><br>下面我们利用训练集数据$\{\mathbf{x},\mathbf{t}\}$，通过极大似然估计来确定未知参数$\mathbf{w}$和${\beta}$的值。假设数据之间相互独立，那么似然函数就是$$p(\mathbf{t}|\mathbf{x},\mathbf{w},\beta)=\prod\limits_{n=1}^N\mathcal{N}(t_n|y(x_n,\mathbf{w}),\beta^{-1})\tag{8}$$<br>似然函数的意义是，在参数$\mathbf{w}$和$\beta$取某个值时，产生这个数据的可能性。那么最可能产生这个数据集的$\mathbf{w}$和$\beta$即能最好拟合曲线的参数，故我们要找到能使似然函数最大化的$\mathbf{w}$和$\beta$。然而通常情况下，直接对似然函数求导会使式子变得更加复杂，所以我们最大化的目标变为似然函数的自然对数。由于对数函数是单调增的，所以对数似然函数与原函数具有相同的最大值点，即我们找到的$\mathbf{w}$和$\beta$仍是正确的。再将正态分布的表达式代入，得到$$\ln p(\mathbf{t}|\mathbf{x},\mathbf{w},\beta)=-\cfrac{\beta}{2}\sum\limits_{n=1}^N\{y(x_n,\mathbf{w})-t_n\}^2+\cfrac{N}{2}\ln\beta-\cfrac{N}{2}\ln(2\pi)\tag{9}$$<br>我们要求得一个$\mathbf{w}_{\mathrm{ML}}$来最大化(9)式，这时可以忽略掉(9)式中的后两项，因为它们不依赖与$\mathbf{w}$。另外，我们注意到乘以一个正常数不会影响$\mathbf{w}_{\mathrm{ML}}$的值，所以我们用$\frac{1}{2}$替换掉$\frac{\beta}{2}$。最后，最大化对数似然函数即最小化它的相反数。故我们将优化目标可以写为：$$\min\cfrac{1}{2}\sum\limits_{n=1}^N\{y(x_n,\mathbf{w})-t_n\}^2$$这和之前的误差函数表达式完全相同！可见，最小化误差平方和和最大化似然函数是等价的。<br>接下来可以求得参数$\beta$的值。最大化(9)式可以得到$$\cfrac{1}{\beta_{\mathrm{ML}}} = \cfrac{1}{N}\sum\limits_{n=1}^N\{y(x_n,\mathbf{w}_{\mathrm{ML}})-t_n\}^2\tag{10}$$求得$\mathbf{w}_{\mathrm{ML}}$和$\beta_{\mathrm{ML}}$之后，我们对于新给定的一个$x$，得到的不再仅仅是一个预测值，而是一个预测出的概率分布$$p(t|x,\mathbf{w}_{\mathrm{ML}},\beta_{\mathrm{ML}})=\mathcal{N}(t|y(x,\mathbf{w}_{\mathrm{ML}}),\beta_{\mathrm{ML}}^{-1})\tag{11}$$</p>
<h3 id="考虑先验概率"><a href="#考虑先验概率" class="headerlink" title="考虑先验概率"></a>考虑先验概率</h3><p>我们假设$\mathbf{w}$服从一个先验分布，简单地，采用正态分布$$p(\mathbf{w}|\alpha)=\mathcal{N}(\mathbf{w}|\mathbf{0},\alpha^{-1}\mathbf{I})=\left(\cfrac{\alpha}{2\pi}\right)^{(M+1)/2}\exp\left\{-\cfrac{\alpha}{2}\mathbf{w}^T\mathbf{w}\right\}\tag{12}$$其中$\alpha$是正态分布的精度，$M+1$是$\mathbf{w}$向量的长度，$M$是多项式的阶数。类似于$\alpha$这样控制模型参数分布的参数，称为<strong>超参数</strong>。利用式(5)，我们可以得到$$p(\mathbf{w}|\mathbf{x},\mathbf{t},\alpha,\beta)\propto p(\mathbf{t}|\mathbf{x},\mathbf{w},\beta)p(\mathbf{w}|\alpha)\tag{13}$$<br>现在我们可以通过最大化后验概率(MAP)的方法来确定$\mathbf{w}$的值。取(13)式的自然对数的相反数，并结合(9)式和(12)式，最大化后验概率即转化成最小化下面的式子$$\frac{\beta}{2}\sum\limits_{n=1}^N\{y(x_n,\mathbf{w})-t_n\}^2+\frac{\alpha}{2}\mathbf{w}^T\mathbf{w}\tag{14}$$这个式子和(2)是相同的的，其中$\lambda=\alpha/\beta$。可见，最大化后验概率和最小化正则化的误差平方和函数是等价的。</p>
<p>参考资料：</p>
<ol>
<li><em>Pattern Recognition and Machine Learning (PRML)<em></em></em></li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/09/26/2016-09-26-贝叶斯与曲线拟合/" data-id="civ37ve8h001uogkroqinvxz9" class="article-share-link">Partager</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/curve-fitting/">curve fitting</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/prml/">prml</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/09/28/2016-09-28-批量梯度下降和随机梯度下降/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Récent</strong>
      <div class="article-nav-title">
        
          批量梯度下降和随机梯度下降
        
      </div>
    </a>
  
  
    <a href="/2016/09/05/2016-09-05-LeetCode-258 & 292 & 136/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Ancien</strong>
      <div class="article-nav-title">LeetCode 136 258 292</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Catégories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/CS229-notes/">CS229 notes</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/LeetCode笔记/">LeetCode笔记</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning-Course-notes/">Machine Learning Course notes</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/PRML-notes/">PRML notes</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Under-Construction/">Under Construction</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/《Algorithms》-notes/">《Algorithms》 notes</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/优化算法/">优化算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/具体数学笔记/">具体数学笔记</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/杂记/">杂记</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Mot-clés</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/a-algorithm/">a* algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/adaboost/">adaboost</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/add-digits/">add digits</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/algorithm/">algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/arithmetic-expression/">arithmetic expression</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/bag/">bag</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/bagging/">bagging</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/batch-gradient-decent/">batch gradient decent</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/beam-search/">beam search</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/best-first-search/">best-first search</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/bfs/">bfs</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/bias/">bias</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/binary-search/">binary search</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/binary-search-tree/">binary search tree</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/curve-fitting/">curve fitting</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dag/">dag</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/data-structure/">data structure</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dfs/">dfs</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/directed-graph/">directed graph</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/exponential-family-distribution/">exponential family distribution</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/forward-stagewise/">forward stagewise</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/gbdt/">gbdt</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/general-linear-model/">general linear model</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hanoi-tower/">hanoi tower</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hash/">hash</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/heap-sort/">heap sort</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/heuristic-algorithm/">heuristic algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo/">hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/insertion-sort/">insertion sort</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/josephus-problem/">josephus problem</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/knight-tour/">knight tour</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kosaraju-s-algorithm/">kosaraju's algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kruskal-s-algorithm/">kruskal's algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/lars/">lars</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/lasso/">lasso</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/leetcode/">leetcode</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linear-regression/">linear regression</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/lingo/">lingo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/logistic-regression/">logistic regression</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/lwr/">lwr</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/">machine learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mathjax/">mathjax</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mst/">mst</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/neural-network/">neural network</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nim-game/">nim game</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/physics/">physics</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/prim-s-algorithm/">prim's algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/priority-queue/">priority queue</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/prml/">prml</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/queue/">queue</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/random-forest/">random forest</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/selection-sort/">selection sort</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/shell-sort/">shell sort</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/single-number/">single number</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/stack/">stack</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/stochastic-gradient-decent/">stochastic gradient decent</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/support-vector-machine/">support vector machine</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/symbol-table/">symbol table</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/topological-sort/">topological sort</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/undirected-graph/">undirected graph</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/variance/">variance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/递归问题/">递归问题</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/集成学习/">集成学习</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Nuage de mot-clés</h3>
    <div class="widget tagcloud">
      <a href="/tags/a-algorithm/" style="font-size: 10px;">a* algorithm</a> <a href="/tags/adaboost/" style="font-size: 10px;">adaboost</a> <a href="/tags/add-digits/" style="font-size: 10px;">add digits</a> <a href="/tags/algorithm/" style="font-size: 20px;">algorithm</a> <a href="/tags/arithmetic-expression/" style="font-size: 10px;">arithmetic expression</a> <a href="/tags/bag/" style="font-size: 10px;">bag</a> <a href="/tags/bagging/" style="font-size: 10px;">bagging</a> <a href="/tags/batch-gradient-decent/" style="font-size: 10px;">batch gradient decent</a> <a href="/tags/beam-search/" style="font-size: 10px;">beam search</a> <a href="/tags/best-first-search/" style="font-size: 10px;">best-first search</a> <a href="/tags/bfs/" style="font-size: 10px;">bfs</a> <a href="/tags/bias/" style="font-size: 10px;">bias</a> <a href="/tags/binary-search/" style="font-size: 10px;">binary search</a> <a href="/tags/binary-search-tree/" style="font-size: 10px;">binary search tree</a> <a href="/tags/curve-fitting/" style="font-size: 10px;">curve fitting</a> <a href="/tags/dag/" style="font-size: 10px;">dag</a> <a href="/tags/data-structure/" style="font-size: 10px;">data structure</a> <a href="/tags/dfs/" style="font-size: 13.33px;">dfs</a> <a href="/tags/directed-graph/" style="font-size: 10px;">directed graph</a> <a href="/tags/exponential-family-distribution/" style="font-size: 10px;">exponential family distribution</a> <a href="/tags/forward-stagewise/" style="font-size: 10px;">forward stagewise</a> <a href="/tags/gbdt/" style="font-size: 10px;">gbdt</a> <a href="/tags/general-linear-model/" style="font-size: 10px;">general linear model</a> <a href="/tags/hanoi-tower/" style="font-size: 10px;">hanoi tower</a> <a href="/tags/hash/" style="font-size: 10px;">hash</a> <a href="/tags/heap-sort/" style="font-size: 10px;">heap sort</a> <a href="/tags/heuristic-algorithm/" style="font-size: 10px;">heuristic algorithm</a> <a href="/tags/hexo/" style="font-size: 13.33px;">hexo</a> <a href="/tags/insertion-sort/" style="font-size: 10px;">insertion sort</a> <a href="/tags/josephus-problem/" style="font-size: 10px;">josephus problem</a> <a href="/tags/knight-tour/" style="font-size: 10px;">knight tour</a> <a href="/tags/kosaraju-s-algorithm/" style="font-size: 10px;">kosaraju's algorithm</a> <a href="/tags/kruskal-s-algorithm/" style="font-size: 10px;">kruskal's algorithm</a> <a href="/tags/lars/" style="font-size: 13.33px;">lars</a> <a href="/tags/lasso/" style="font-size: 13.33px;">lasso</a> <a href="/tags/leetcode/" style="font-size: 10px;">leetcode</a> <a href="/tags/linear-regression/" style="font-size: 10px;">linear regression</a> <a href="/tags/lingo/" style="font-size: 10px;">lingo</a> <a href="/tags/logistic-regression/" style="font-size: 10px;">logistic regression</a> <a href="/tags/lwr/" style="font-size: 10px;">lwr</a> <a href="/tags/machine-learning/" style="font-size: 16.67px;">machine learning</a> <a href="/tags/mathjax/" style="font-size: 10px;">mathjax</a> <a href="/tags/mst/" style="font-size: 10px;">mst</a> <a href="/tags/neural-network/" style="font-size: 10px;">neural network</a> <a href="/tags/nim-game/" style="font-size: 10px;">nim game</a> <a href="/tags/physics/" style="font-size: 10px;">physics</a> <a href="/tags/prim-s-algorithm/" style="font-size: 10px;">prim's algorithm</a> <a href="/tags/priority-queue/" style="font-size: 10px;">priority queue</a> <a href="/tags/prml/" style="font-size: 10px;">prml</a> <a href="/tags/queue/" style="font-size: 10px;">queue</a> <a href="/tags/random-forest/" style="font-size: 10px;">random forest</a> <a href="/tags/selection-sort/" style="font-size: 10px;">selection sort</a> <a href="/tags/shell-sort/" style="font-size: 10px;">shell sort</a> <a href="/tags/single-number/" style="font-size: 10px;">single number</a> <a href="/tags/stack/" style="font-size: 10px;">stack</a> <a href="/tags/stochastic-gradient-decent/" style="font-size: 10px;">stochastic gradient decent</a> <a href="/tags/support-vector-machine/" style="font-size: 10px;">support vector machine</a> <a href="/tags/symbol-table/" style="font-size: 13.33px;">symbol table</a> <a href="/tags/topological-sort/" style="font-size: 10px;">topological sort</a> <a href="/tags/undirected-graph/" style="font-size: 10px;">undirected graph</a> <a href="/tags/variance/" style="font-size: 10px;">variance</a> <a href="/tags/递归问题/" style="font-size: 10px;">递归问题</a> <a href="/tags/集成学习/" style="font-size: 10px;">集成学习</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">June 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2000/07/">July 2000</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2000/05/">May 2000</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Articles récents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/11/04/2016-11-04-Gradient-Boosting/">梯度提升(Gradient Boosting)</a>
          </li>
        
          <li>
            <a href="/2016/10/28/2016-10-28-lars-lasso-stagewise/">LARS与Lasso和Forward Stagewise</a>
          </li>
        
          <li>
            <a href="/2016/10/26/2016-10-26-Least-Angle-Regression/">最小角回归(Least Angle Regression)</a>
          </li>
        
          <li>
            <a href="/2016/10/17/2016-10-17-集成学习算法/">集成学习算法(Ensemble Learning)</a>
          </li>
        
          <li>
            <a href="/2016/10/14/2016-10-14-General-Linear-Model/">一般线性模型(General Linear Model)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Wang Kx<br>
      Propulsé by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>